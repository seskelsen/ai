[
    {
        "label": "load_iris",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "load_iris",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "load_iris",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "load_iris",
        "importPath": "sklearn.datasets",
        "description": "sklearn.datasets",
        "isExtraImport": true,
        "detail": "sklearn.datasets",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "DecisionTreeClassifier",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "DecisionTreeClassifier",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "DecisionTreeClassifier",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "DecisionTreeClassifier",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "tree",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "tree",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "tree",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "tree",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "sysconfig",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sysconfig",
        "description": "sysconfig",
        "detail": "sysconfig",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616213948",
        "description": ".history.arvorededecisao_20240616213948",
        "peekOfCode": "data = load_iris()\nX = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)",
        "detail": ".history.arvorededecisao_20240616213948",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616213948",
        "description": ".history.arvorededecisao_20240616213948",
        "peekOfCode": "X = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)",
        "detail": ".history.arvorededecisao_20240616213948",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616213948",
        "description": ".history.arvorededecisao_20240616213948",
        "peekOfCode": "y = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")",
        "detail": ".history.arvorededecisao_20240616213948",
        "documentation": {}
    },
    {
        "label": "clf",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616213948",
        "description": ".history.arvorededecisao_20240616213948",
        "peekOfCode": "clf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616213948",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616213948",
        "description": ".history.arvorededecisao_20240616213948",
        "peekOfCode": "y_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616213948",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616213948",
        "description": ".history.arvorededecisao_20240616213948",
        "peekOfCode": "accuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616213948",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214254",
        "description": ".history.arvorededecisao_20240616214254",
        "peekOfCode": "data = load_iris()\nX = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)",
        "detail": ".history.arvorededecisao_20240616214254",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214254",
        "description": ".history.arvorededecisao_20240616214254",
        "peekOfCode": "X = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)",
        "detail": ".history.arvorededecisao_20240616214254",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214254",
        "description": ".history.arvorededecisao_20240616214254",
        "peekOfCode": "y = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")",
        "detail": ".history.arvorededecisao_20240616214254",
        "documentation": {}
    },
    {
        "label": "clf",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214254",
        "description": ".history.arvorededecisao_20240616214254",
        "peekOfCode": "clf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616214254",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214254",
        "description": ".history.arvorededecisao_20240616214254",
        "peekOfCode": "y_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616214254",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214254",
        "description": ".history.arvorededecisao_20240616214254",
        "peekOfCode": "accuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616214254",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214532",
        "description": ".history.arvorededecisao_20240616214532",
        "peekOfCode": "data = load_iris()\nX = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)",
        "detail": ".history.arvorededecisao_20240616214532",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214532",
        "description": ".history.arvorededecisao_20240616214532",
        "peekOfCode": "X = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)",
        "detail": ".history.arvorededecisao_20240616214532",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214532",
        "description": ".history.arvorededecisao_20240616214532",
        "peekOfCode": "y = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")",
        "detail": ".history.arvorededecisao_20240616214532",
        "documentation": {}
    },
    {
        "label": "clf",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214532",
        "description": ".history.arvorededecisao_20240616214532",
        "peekOfCode": "clf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616214532",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214532",
        "description": ".history.arvorededecisao_20240616214532",
        "peekOfCode": "y_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616214532",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 5,
        "importPath": ".history.arvorededecisao_20240616214532",
        "description": ".history.arvorededecisao_20240616214532",
        "peekOfCode": "accuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": ".history.arvorededecisao_20240616214532",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": ".history.entropy_20240616213645",
        "description": ".history.entropy_20240616213645",
        "peekOfCode": "def entropy(labels):\n    # Calcula as proporções de cada classe\n    _, counts = np.unique(labels, return_counts=True)\n    probabilities = counts / counts.sum()\n    # Calcula a entropia\n    entropy = -np.sum(probabilities * np.log2(probabilities))\n    return entropy\n# Exemplo de uso\nlabels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\nprint(\"Entropia:\", entropy(labels))",
        "detail": ".history.entropy_20240616213645",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": ".history.entropy_20240616213645",
        "description": ".history.entropy_20240616213645",
        "peekOfCode": "labels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\nprint(\"Entropia:\", entropy(labels))",
        "detail": ".history.entropy_20240616213645",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": ".history.entropy_20240616213856",
        "description": ".history.entropy_20240616213856",
        "peekOfCode": "def entropy(labels):\n    # Calcula as proporções de cada classe\n    _, counts = np.unique(labels, return_counts=True)\n    probabilities = counts / counts.sum()\n    # Calcula a entropia\n    entropy = -np.sum(probabilities * np.log2(probabilities))\n    return entropy\n# Exemplo de uso\nlabels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\nresult = entropy(labels)",
        "detail": ".history.entropy_20240616213856",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": ".history.entropy_20240616213856",
        "description": ".history.entropy_20240616213856",
        "peekOfCode": "labels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\nresult = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": ".history.entropy_20240616213856",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": ".history.entropy_20240616213856",
        "description": ".history.entropy_20240616213856",
        "peekOfCode": "result = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": ".history.entropy_20240616213856",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": ".history.entropy_20240616214645",
        "description": ".history.entropy_20240616214645",
        "peekOfCode": "def entropy(labels):\n    # Calcula as proporções de cada classe\n    _, counts = np.unique(labels, return_counts=True)\n    probabilities = counts / counts.sum()\n    # Calcula a entropia\n    entropy = -np.sum(probabilities * np.log2(probabilities))\n    return entropy\n# Exemplo de uso\nlabels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\nresult = entropy(labels)",
        "detail": ".history.entropy_20240616214645",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": ".history.entropy_20240616214645",
        "description": ".history.entropy_20240616214645",
        "peekOfCode": "labels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\nresult = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": ".history.entropy_20240616214645",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": ".history.entropy_20240616214645",
        "description": ".history.entropy_20240616214645",
        "peekOfCode": "result = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": ".history.entropy_20240616214645",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": ".history.entropy_20240616214907",
        "description": ".history.entropy_20240616214907",
        "peekOfCode": "def entropy(labels):\n    # Calcula as proporções de cada classe\n    _, counts = np.unique(labels, return_counts=True)\n    probabilities = counts / counts.sum()\n    # Calcula a entropia\n    entropy = -np.sum(probabilities * np.log2(probabilities))\n    return entropy\n# Exemplo de uso\nlabels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\n# print(\"Entropia:\", entropy(labels))",
        "detail": ".history.entropy_20240616214907",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": ".history.entropy_20240616214907",
        "description": ".history.entropy_20240616214907",
        "peekOfCode": "labels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\n# print(\"Entropia:\", entropy(labels))\nresult = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": ".history.entropy_20240616214907",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": ".history.entropy_20240616214907",
        "description": ".history.entropy_20240616214907",
        "peekOfCode": "result = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": ".history.entropy_20240616214907",
        "documentation": {}
    },
    {
        "label": "resultados",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095738",
        "description": ".history.MetricasMatrixConfusao_20240614095738",
        "peekOfCode": "resultados = [\n    {\"real\": \"positivo\", \"predito\": \"positivo\"},\n    {\"real\": \"negativo\", \"predito\": \"positivo\"},\n    {\"real\": \"positivo\", \"predito\": \"negativo\"},\n    {\"real\": \"negativo\", \"predito\": \"negativo\"}\n    # Adicione mais resultados aqui...\n]\n# Inicializando contadores\nTP, FN, FP, TN = 0, 0, 0, 0\n# Contando os valores",
        "detail": ".history.MetricasMatrixConfusao_20240614095738",
        "documentation": {}
    },
    {
        "label": "matriz_confusao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095738",
        "description": ".history.MetricasMatrixConfusao_20240614095738",
        "peekOfCode": "matriz_confusao = [\n    [TP, FN],\n    [FP, TN]\n]\n# Calculando as métricas\nacuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados",
        "detail": ".history.MetricasMatrixConfusao_20240614095738",
        "documentation": {}
    },
    {
        "label": "acuracia",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095738",
        "description": ".history.MetricasMatrixConfusao_20240614095738",
        "peekOfCode": "acuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095738",
        "documentation": {}
    },
    {
        "label": "precisao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095738",
        "description": ".history.MetricasMatrixConfusao_20240614095738",
        "peekOfCode": "precisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095738",
        "documentation": {}
    },
    {
        "label": "revocacao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095738",
        "description": ".history.MetricasMatrixConfusao_20240614095738",
        "peekOfCode": "revocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095738",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095738",
        "description": ".history.MetricasMatrixConfusao_20240614095738",
        "peekOfCode": "f1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095738",
        "documentation": {}
    },
    {
        "label": "resultados",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095824",
        "description": ".history.MetricasMatrixConfusao_20240614095824",
        "peekOfCode": "resultados = [\n    {\"real\": \"positivo\", \"predito\": \"positivo\"},\n    {\"real\": \"negativo\", \"predito\": \"positivo\"},\n    {\"real\": \"positivo\", \"predito\": \"negativo\"},\n    {\"real\": \"negativo\", \"predito\": \"negativo\"}\n    # Adicione mais resultados aqui...\n]\n# Inicializando contadores\nTP, FN, FP, TN = 0, 0, 0, 0\n# Contando os valores",
        "detail": ".history.MetricasMatrixConfusao_20240614095824",
        "documentation": {}
    },
    {
        "label": "matriz_confusao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095824",
        "description": ".history.MetricasMatrixConfusao_20240614095824",
        "peekOfCode": "matriz_confusao = [\n    [TP, FN],\n    [FP, TN]\n]\n# Calculando as métricas\nacuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados",
        "detail": ".history.MetricasMatrixConfusao_20240614095824",
        "documentation": {}
    },
    {
        "label": "acuracia",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095824",
        "description": ".history.MetricasMatrixConfusao_20240614095824",
        "peekOfCode": "acuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095824",
        "documentation": {}
    },
    {
        "label": "precisao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095824",
        "description": ".history.MetricasMatrixConfusao_20240614095824",
        "peekOfCode": "precisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095824",
        "documentation": {}
    },
    {
        "label": "revocacao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095824",
        "description": ".history.MetricasMatrixConfusao_20240614095824",
        "peekOfCode": "revocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095824",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095824",
        "description": ".history.MetricasMatrixConfusao_20240614095824",
        "peekOfCode": "f1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095824",
        "documentation": {}
    },
    {
        "label": "resultados",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095905",
        "description": ".history.MetricasMatrixConfusao_20240614095905",
        "peekOfCode": "resultados = [\n    {\"real\": \"positivo\", \"predito\": \"positivo\"},\n    {\"real\": \"negativo\", \"predito\": \"positivo\"},\n    {\"real\": \"positivo\", \"predito\": \"negativo\"},\n    {\"real\": \"negativo\", \"predito\": \"negativo\"}\n    # Adicione mais resultados aqui...\n]\n# Inicializando contadores\nTP, FN, FP, TN = 0, 0, 0, 0\n# Contando os valores",
        "detail": ".history.MetricasMatrixConfusao_20240614095905",
        "documentation": {}
    },
    {
        "label": "matriz_confusao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095905",
        "description": ".history.MetricasMatrixConfusao_20240614095905",
        "peekOfCode": "matriz_confusao = [\n    [TP, FN],\n    [FP, TN]\n]\n# Calculando as métricas\nacuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados",
        "detail": ".history.MetricasMatrixConfusao_20240614095905",
        "documentation": {}
    },
    {
        "label": "acuracia",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095905",
        "description": ".history.MetricasMatrixConfusao_20240614095905",
        "peekOfCode": "acuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095905",
        "documentation": {}
    },
    {
        "label": "precisao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095905",
        "description": ".history.MetricasMatrixConfusao_20240614095905",
        "peekOfCode": "precisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095905",
        "documentation": {}
    },
    {
        "label": "revocacao",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095905",
        "description": ".history.MetricasMatrixConfusao_20240614095905",
        "peekOfCode": "revocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095905",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "kind": 5,
        "importPath": ".history.MetricasMatrixConfusao_20240614095905",
        "description": ".history.MetricasMatrixConfusao_20240614095905",
        "peekOfCode": "f1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": ".history.MetricasMatrixConfusao_20240614095905",
        "documentation": {}
    },
    {
        "label": "Tee",
        "kind": 6,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "class Tee:\n    def __init__(self, file):\n        self.f = file\n    def write(self, what):\n        if self.f is not None:\n            try:\n                self.f.write(what.replace(\"\\n\", \"\\r\\n\"))\n            except IOError:\n                pass\n        tee_f.write(what)",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "CopyTo",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def CopyTo(desc, src, dest):\n    import win32api\n    import win32con\n    while 1:\n        try:\n            win32api.CopyFile(src, dest, 0)\n            return\n        except win32api.error as details:\n            if details.winerror == 5:  # access denied - user not admin.\n                raise",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "LoadSystemModule",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def LoadSystemModule(lib_dir, modname):\n    # See if this is a debug build.\n    import importlib.machinery\n    import importlib.util\n    suffix = \"_d\" if \"_d.pyd\" in importlib.machinery.EXTENSION_SUFFIXES else \"\"\n    filename = \"%s%d%d%s.dll\" % (\n        modname,\n        sys.version_info[0],\n        sys.version_info[1],\n        suffix,",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "SetPyKeyVal",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def SetPyKeyVal(key_name, value_name, value):\n    root_hkey = get_root_hkey()\n    root_key = winreg.OpenKey(root_hkey, root_key_name)\n    try:\n        my_key = winreg.CreateKey(root_key, key_name)\n        try:\n            winreg.SetValueEx(my_key, value_name, 0, winreg.REG_SZ, value)\n            if verbose:\n                print(\"-> %s\\\\%s[%s]=%r\" % (root_key_name, key_name, value_name, value))\n        finally:",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "UnsetPyKeyVal",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def UnsetPyKeyVal(key_name, value_name, delete_key=False):\n    root_hkey = get_root_hkey()\n    root_key = winreg.OpenKey(root_hkey, root_key_name)\n    try:\n        my_key = winreg.OpenKey(root_key, key_name, 0, winreg.KEY_SET_VALUE)\n        try:\n            winreg.DeleteValue(my_key, value_name)\n            if verbose:\n                print(\"-> DELETE %s\\\\%s[%s]\" % (root_key_name, key_name, value_name))\n        finally:",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "RegisterCOMObjects",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def RegisterCOMObjects(register=True):\n    import win32com.server.register\n    if register:\n        func = win32com.server.register.RegisterClasses\n    else:\n        func = win32com.server.register.UnregisterClasses\n    flags = {}\n    if not verbose:\n        flags[\"quiet\"] = 1\n    for module, klass_name in com_modules:",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "RegisterHelpFile",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def RegisterHelpFile(register=True, lib_dir=None):\n    if lib_dir is None:\n        lib_dir = sysconfig.get_paths()[\"platlib\"]\n    if register:\n        # Register the .chm help file.\n        chm_file = os.path.join(lib_dir, \"PyWin32.chm\")\n        if os.path.isfile(chm_file):\n            # This isn't recursive, so if 'Help' doesn't exist, we croak\n            SetPyKeyVal(\"Help\", None, None)\n            SetPyKeyVal(\"Help\\\\Pythonwin Reference\", None, chm_file)",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "RegisterPythonwin",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def RegisterPythonwin(register=True, lib_dir=None):\n    \"\"\"Add (or remove) Pythonwin to context menu for python scripts.\n    ??? Should probably also add Edit command for pys files also.\n    Also need to remove these keys on uninstall, but there's no function\n        like file_created to add registry entries to uninstall log ???\n    \"\"\"\n    import os\n    if lib_dir is None:\n        lib_dir = sysconfig.get_paths()[\"platlib\"]\n    classes_root = get_root_hkey()",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "get_shortcuts_folder",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def get_shortcuts_folder():\n    if get_root_hkey() == winreg.HKEY_LOCAL_MACHINE:\n        try:\n            fldr = get_special_folder_path(\"CSIDL_COMMON_PROGRAMS\")\n        except OSError:\n            # No CSIDL_COMMON_PROGRAMS on this platform\n            fldr = get_special_folder_path(\"CSIDL_PROGRAMS\")\n    else:\n        # non-admin install - always goes in this user's start menu.\n        fldr = get_special_folder_path(\"CSIDL_PROGRAMS\")",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "get_system_dir",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def get_system_dir():\n    import win32api  # we assume this exists.\n    try:\n        import pythoncom\n        import win32process\n        from win32com.shell import shell, shellcon\n        try:\n            if win32process.IsWow64Process():\n                return shell.SHGetSpecialFolderPath(0, shellcon.CSIDL_SYSTEMX86)\n            return shell.SHGetSpecialFolderPath(0, shellcon.CSIDL_SYSTEM)",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "fixup_dbi",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def fixup_dbi():\n    # We used to have a dbi.pyd with our .pyd files, but now have a .py file.\n    # If the user didn't uninstall, they will find the .pyd which will cause\n    # problems - so handle that.\n    import win32api\n    import win32con\n    pyd_name = os.path.join(os.path.dirname(win32api.__file__), \"dbi.pyd\")\n    pyd_d_name = os.path.join(os.path.dirname(win32api.__file__), \"dbi_d.pyd\")\n    py_name = os.path.join(os.path.dirname(win32con.__file__), \"dbi.py\")\n    for this_pyd in (pyd_name, pyd_d_name):",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "install",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def install(lib_dir):\n    import traceback\n    # The .pth file is now installed as a regular file.\n    # Create the .pth file in the site-packages dir, and use only relative paths\n    # We used to write a .pth directly to sys.prefix - clobber it.\n    if os.path.isfile(os.path.join(sys.prefix, \"pywin32.pth\")):\n        os.unlink(os.path.join(sys.prefix, \"pywin32.pth\"))\n    # The .pth may be new and therefore not loaded in this session.\n    # Setup the paths just in case.\n    for name in \"win32 win32\\\\lib Pythonwin\".split():",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "uninstall",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def uninstall(lib_dir):\n    # First ensure our system modules are loaded from pywin32_system, so\n    # we can remove the ones we copied...\n    LoadSystemModule(lib_dir, \"pywintypes\")\n    LoadSystemModule(lib_dir, \"pythoncom\")\n    try:\n        RegisterCOMObjects(False)\n    except Exception as why:\n        print(\"Failed to unregister COM objects: %s\" % (why,))\n    try:",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "verify_destination",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def verify_destination(location):\n    if not os.path.isdir(location):\n        raise argparse.ArgumentTypeError('Path \"{}\" does not exist!'.format(location))\n    return location\ndef main():\n    import argparse\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\"\"\"A post-install script for the pywin32 extensions.\n    * Typical usage:",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "def main():\n    import argparse\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description=\"\"\"A post-install script for the pywin32 extensions.\n    * Typical usage:\n    > python pywin32_postinstall.py -install\n    If you installed pywin32 via a .exe installer, this should be run\n    automatically after installation, but if it fails you can run it again.\n    If you installed pywin32 via PIP, you almost certainly need to run this to",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "tee_f",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "tee_f = open(os.path.join(tempfile.gettempdir(), \"pywin32_postinstall.log\"), \"w\")\nclass Tee:\n    def __init__(self, file):\n        self.f = file\n    def write(self, what):\n        if self.f is not None:\n            try:\n                self.f.write(what.replace(\"\\n\", \"\\r\\n\"))\n            except IOError:\n                pass",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "sys.stderr",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "sys.stderr = Tee(sys.stderr)\nsys.stdout = Tee(sys.stdout)\ncom_modules = [\n    # module_name,                      class_names\n    (\"win32com.servers.interp\", \"Interpreter\"),\n    (\"win32com.servers.dictionary\", \"DictionaryPolicy\"),\n    (\"win32com.axscript.client.pyscript\", \"PyScript\"),\n]\n# Is this a 'silent' install - ie, avoid all dialogs.\n# Different than 'verbose'",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "sys.stdout",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "sys.stdout = Tee(sys.stdout)\ncom_modules = [\n    # module_name,                      class_names\n    (\"win32com.servers.interp\", \"Interpreter\"),\n    (\"win32com.servers.dictionary\", \"DictionaryPolicy\"),\n    (\"win32com.axscript.client.pyscript\", \"PyScript\"),\n]\n# Is this a 'silent' install - ie, avoid all dialogs.\n# Different than 'verbose'\nsilent = 0",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "com_modules",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "com_modules = [\n    # module_name,                      class_names\n    (\"win32com.servers.interp\", \"Interpreter\"),\n    (\"win32com.servers.dictionary\", \"DictionaryPolicy\"),\n    (\"win32com.axscript.client.pyscript\", \"PyScript\"),\n]\n# Is this a 'silent' install - ie, avoid all dialogs.\n# Different than 'verbose'\nsilent = 0\n# Verbosity of output messages.",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "silent",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "silent = 0\n# Verbosity of output messages.\nverbose = 1\nroot_key_name = \"Software\\\\Python\\\\PythonCore\\\\\" + sys.winver\ntry:\n    # When this script is run from inside the bdist_wininst installer,\n    # file_created() and directory_created() are additional builtin\n    # functions which write lines to Python23\\pywin32-install.log. This is\n    # a list of actions for the uninstaller, the format is inspired by what\n    # the Wise installer also creates.",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "verbose",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "verbose = 1\nroot_key_name = \"Software\\\\Python\\\\PythonCore\\\\\" + sys.winver\ntry:\n    # When this script is run from inside the bdist_wininst installer,\n    # file_created() and directory_created() are additional builtin\n    # functions which write lines to Python23\\pywin32-install.log. This is\n    # a list of actions for the uninstaller, the format is inspired by what\n    # the Wise installer also creates.\n    file_created\n    is_bdist_wininst = True",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "root_key_name",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_postinstall",
        "description": ".venv.Scripts.pywin32_postinstall",
        "peekOfCode": "root_key_name = \"Software\\\\Python\\\\PythonCore\\\\\" + sys.winver\ntry:\n    # When this script is run from inside the bdist_wininst installer,\n    # file_created() and directory_created() are additional builtin\n    # functions which write lines to Python23\\pywin32-install.log. This is\n    # a list of actions for the uninstaller, the format is inspired by what\n    # the Wise installer also creates.\n    file_created\n    is_bdist_wininst = True\nexcept NameError:",
        "detail": ".venv.Scripts.pywin32_postinstall",
        "documentation": {}
    },
    {
        "label": "run_test",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_testall",
        "description": ".venv.Scripts.pywin32_testall",
        "peekOfCode": "def run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)\n    # some tests prefer to be run from their directory.\n    cmd = [sys.executable, \"-u\", scriptname] + cmdline_extras\n    print(\"--- Running '%s' ---\" % script)\n    sys.stdout.flush()\n    result = subprocess.run(cmd, check=False, cwd=dirname)\n    print(\"*** Test script '%s' exited with %s\" % (script, result.returncode))\n    sys.stdout.flush()\n    if result.returncode:",
        "detail": ".venv.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "find_and_run",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_testall",
        "description": ".venv.Scripts.pywin32_testall",
        "peekOfCode": "def find_and_run(possible_locations, extras):\n    for maybe in possible_locations:\n        if os.path.isfile(maybe):\n            run_test(maybe, extras)\n            break\n    else:\n        raise RuntimeError(\n            \"Failed to locate a test script in one of %s\" % possible_locations\n        )\ndef main():",
        "detail": ".venv.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".venv.Scripts.pywin32_testall",
        "description": ".venv.Scripts.pywin32_testall",
        "peekOfCode": "def main():\n    import argparse\n    code_directories = [this_dir] + site_packages\n    parser = argparse.ArgumentParser(\n        description=\"A script to trigger tests in all subprojects of PyWin32.\"\n    )\n    parser.add_argument(\n        \"-no-user-interaction\",\n        default=False,\n        action=\"store_true\",",
        "detail": ".venv.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "this_dir",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_testall",
        "description": ".venv.Scripts.pywin32_testall",
        "peekOfCode": "this_dir = os.path.dirname(__file__)\nsite_packages = [\n    site.getusersitepackages(),\n] + site.getsitepackages()\nfailures = []\n# Run a test using subprocess and wait for the result.\n# If we get an returncode != 0, we know that there was an error, but we don't\n# abort immediately - we run as many tests as we can.\ndef run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)",
        "detail": ".venv.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "site_packages",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_testall",
        "description": ".venv.Scripts.pywin32_testall",
        "peekOfCode": "site_packages = [\n    site.getusersitepackages(),\n] + site.getsitepackages()\nfailures = []\n# Run a test using subprocess and wait for the result.\n# If we get an returncode != 0, we know that there was an error, but we don't\n# abort immediately - we run as many tests as we can.\ndef run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)\n    # some tests prefer to be run from their directory.",
        "detail": ".venv.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "failures",
        "kind": 5,
        "importPath": ".venv.Scripts.pywin32_testall",
        "description": ".venv.Scripts.pywin32_testall",
        "peekOfCode": "failures = []\n# Run a test using subprocess and wait for the result.\n# If we get an returncode != 0, we know that there was an error, but we don't\n# abort immediately - we run as many tests as we can.\ndef run_test(script, cmdline_extras):\n    dirname, scriptname = os.path.split(script)\n    # some tests prefer to be run from their directory.\n    cmd = [sys.executable, \"-u\", scriptname] + cmdline_extras\n    print(\"--- Running '%s' ---\" % script)\n    sys.stdout.flush()",
        "detail": ".venv.Scripts.pywin32_testall",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "arvorededecisao",
        "description": "arvorededecisao",
        "peekOfCode": "data = load_iris()\nX = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)",
        "detail": "arvorededecisao",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "arvorededecisao",
        "description": "arvorededecisao",
        "peekOfCode": "X = data.data\ny = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)",
        "detail": "arvorededecisao",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "arvorededecisao",
        "description": "arvorededecisao",
        "peekOfCode": "y = data.target\n# Dividir o conjunto de dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Construir o classificador de árvore de decisão\nclf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")",
        "detail": "arvorededecisao",
        "documentation": {}
    },
    {
        "label": "clf",
        "kind": 5,
        "importPath": "arvorededecisao",
        "description": "arvorededecisao",
        "peekOfCode": "clf = DecisionTreeClassifier(criterion='entropy')\nclf.fit(X_train, y_train)\n# Previsão e avaliação\ny_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": "arvorededecisao",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "arvorededecisao",
        "description": "arvorededecisao",
        "peekOfCode": "y_pred = clf.predict(X_test)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": "arvorededecisao",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 5,
        "importPath": "arvorededecisao",
        "description": "arvorededecisao",
        "peekOfCode": "accuracy = np.mean(y_pred == y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\n# Visualizar a árvore de decisão\nplt.figure(figsize=(20,10))\ntree.plot_tree(clf, filled=True, feature_names=data.feature_names, class_names=data.target_names)\nplt.show()",
        "detail": "arvorededecisao",
        "documentation": {}
    },
    {
        "label": "entropy",
        "kind": 2,
        "importPath": "entropy",
        "description": "entropy",
        "peekOfCode": "def entropy(labels):\n    # Calcula as proporções de cada classe\n    _, counts = np.unique(labels, return_counts=True)\n    probabilities = counts / counts.sum()\n    # Calcula a entropia\n    entropy = -np.sum(probabilities * np.log2(probabilities))\n    return entropy\n# Exemplo de uso\nlabels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\n# print(\"Entropia:\", entropy(labels))",
        "detail": "entropy",
        "documentation": {}
    },
    {
        "label": "labels",
        "kind": 5,
        "importPath": "entropy",
        "description": "entropy",
        "peekOfCode": "labels = ['False', 'False', 'False', 'True', 'True', 'True', 'True', 'True']\n# print(\"Entropia:\", entropy(labels))\nresult = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": "entropy",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "entropy",
        "description": "entropy",
        "peekOfCode": "result = entropy(labels)\nprint(\"Entropia: {result}\")",
        "detail": "entropy",
        "documentation": {}
    },
    {
        "label": "resultados",
        "kind": 5,
        "importPath": "MetricasMatrizConfusao",
        "description": "MetricasMatrizConfusao",
        "peekOfCode": "resultados = [\n    {\"real\": \"positivo\", \"predito\": \"positivo\"},\n    {\"real\": \"negativo\", \"predito\": \"positivo\"},\n    {\"real\": \"positivo\", \"predito\": \"negativo\"},\n    {\"real\": \"negativo\", \"predito\": \"negativo\"}\n    # Adicione mais resultados aqui...\n]\n# Inicializando contadores\nTP, FN, FP, TN = 0, 0, 0, 0\n# Contando os valores",
        "detail": "MetricasMatrizConfusao",
        "documentation": {}
    },
    {
        "label": "matriz_confusao",
        "kind": 5,
        "importPath": "MetricasMatrizConfusao",
        "description": "MetricasMatrizConfusao",
        "peekOfCode": "matriz_confusao = [\n    [TP, FN],\n    [FP, TN]\n]\n# Calculando as métricas\nacuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados",
        "detail": "MetricasMatrizConfusao",
        "documentation": {}
    },
    {
        "label": "acuracia",
        "kind": 5,
        "importPath": "MetricasMatrizConfusao",
        "description": "MetricasMatrizConfusao",
        "peekOfCode": "acuracia = (TP + TN) / (TP + FN + FP + TN)\nprecisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": "MetricasMatrizConfusao",
        "documentation": {}
    },
    {
        "label": "precisao",
        "kind": 5,
        "importPath": "MetricasMatrizConfusao",
        "description": "MetricasMatrizConfusao",
        "peekOfCode": "precisao = TP / (TP + FP)\nrevocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": "MetricasMatrizConfusao",
        "documentation": {}
    },
    {
        "label": "revocacao",
        "kind": 5,
        "importPath": "MetricasMatrizConfusao",
        "description": "MetricasMatrizConfusao",
        "peekOfCode": "revocacao = TP / (TP + FN)\nf1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": "MetricasMatrizConfusao",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "kind": 5,
        "importPath": "MetricasMatrizConfusao",
        "description": "MetricasMatrizConfusao",
        "peekOfCode": "f1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n# Exibindo os resultados\nprint(\"Matriz de Confusão:\", matriz_confusao)\nprint(\"Acurácia:\", acuracia)\nprint(\"Precisão:\", precisao)\nprint(\"Revocação:\", revocacao)\nprint(\"F1-Score:\", f1_score)",
        "detail": "MetricasMatrizConfusao",
        "documentation": {}
    }
]